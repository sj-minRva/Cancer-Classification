{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVPawgH4sqj0hVy7rqDFJO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sj-minRva/Cancer-Classification/blob/main/Lung_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNSEKf6WYWXd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score, cohen_kappa_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.utils import shuffle\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"Lung_gene_expression.csv\", index_col=\"Unnamed: 0\")\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "# Encode the target variable\n",
        "le = LabelEncoder()\n",
        "df[\"classes\"] = le.fit_transform(df[\"classes\"])  # Convert categorical labels to 0 and 1\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=[\"classes\"])\n",
        "y = df[\"classes\"]\n",
        "\n",
        "# Split dataset into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "6R107DnGYdWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:,1:]\n"
      ],
      "metadata": {
        "id": "_QUvQVxdYiH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna()\n"
      ],
      "metadata": {
        "id": "31eYTnqTYjmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Get feature importances\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# Create a DataFrame for importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Gene': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Select Top 1000 Genes\n",
        "# ---------------------------\n",
        "top_genes_df = importance_df.sort_values(by='Importance', ascending=False).head(1000)\n",
        "\n",
        "# Optional: Save to CSV\n",
        "top_genes_df.to_csv('top_1000_genes.csv', index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# DONE!\n",
        "# ---------------------------\n",
        "print(\"Top 1000 genes saved to 'top_1000_genes.csv'\")"
      ],
      "metadata": {
        "id": "Z6JASNS7YopE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# None + RF"
      ],
      "metadata": {
        "id": "R8YJXDcfYrfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf.predict(X_test)\n",
        "y_pred_proba = rf.predict_proba(X_test)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"Kappa: {kappa:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "qPAWosLyYuLF",
        "outputId": "f6705339-2e66-44f0-ab0a-7efdb657b4e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'RandomForestClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-29921276.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize and train the Random Forest classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# none + XGB"
      ],
      "metadata": {
        "id": "FlOACUfKY1D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#None + XGB\n",
        "# Initialize and train the XGBoost classifier\n",
        "xgb_clf = xgb.XGBClassifier(n_estimators=100, random_state=42, eval_metric=\"logloss\")\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "y_pred_proba = xgb_clf.predict_proba(X_test)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"Kappa: {kappa:.4f}\")\n"
      ],
      "metadata": {
        "id": "AXDBjxk7Y4jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# none + LR"
      ],
      "metadata": {
        "id": "5k8fUY2LY63f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Logistic Regression model\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import pandas as pd\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lr.predict(X_test)\n",
        "y_pred_proba = lr.predict_proba(X_test)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "scores = cross_val_score(lr, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(np.unique(y_pred, return_counts=True))\n",
        "\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"cvs:\",scores.mean())\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"Kappa: {kappa:.4f}\")"
      ],
      "metadata": {
        "id": "4VHg0khzY-6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# None + SVM"
      ],
      "metadata": {
        "id": "zRaUdtzsZCxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the SVM model (with probability=True for AUC calculation)\n",
        "svm_clf = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svm_clf.predict(X_test)\n",
        "y_pred_proba = svm_clf.predict_proba(X_test)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"Kappa: {kappa:.4f}\")"
      ],
      "metadata": {
        "id": "mZ5K-66tZIX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGB + SVM"
      ],
      "metadata": {
        "id": "HRdjJgUWZP6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Train XGBoost to get feature importances\n",
        "xgb_selector = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6,\n",
        "                             subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
        "                             use_label_encoder=False, eval_metric=\"logloss\")\n",
        "\n",
        "xgb_selector.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(xgb_selector.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Standardize the features (important for SVM)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train SVM classifier\n",
        "    svm_clf = SVC(kernel=\"rbf\", C=1.0, probability=True, random_state=42)\n",
        "    svm_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = svm_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = svm_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "3WHgA4nfZS97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGB + LR"
      ],
      "metadata": {
        "id": "hNAfJz73ZWRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train XGBoost to get feature importances\n",
        "xgb_selector = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6,\n",
        "                             subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
        "                             use_label_encoder=False, eval_metric=\"logloss\")\n",
        "\n",
        "xgb_selector.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(xgb_selector.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Standardize the features (important for Logistic Regression)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "    X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "    # Train Logistic Regression classifier\n",
        "    lr_clf = LogisticRegression(solver=\"liblinear\", C=1.0, random_state=42)\n",
        "    lr_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = lr_clf.predict(X_test_scaled)\n",
        "    y_pred_proba = lr_clf.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "4VbZo6AEZn8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGB + RF"
      ],
      "metadata": {
        "id": "DToUpU9AZsIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train XGBoost to get feature importances\n",
        "xgb_selector = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6,\n",
        "                             subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
        "                             use_label_encoder=False, eval_metric=\"logloss\")\n",
        "\n",
        "xgb_selector.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(xgb_selector.feature_importances_, index=X.columns)\n",
        "\n",
        "# List of feature selection counts\n",
        "feature_counts = [10, 50, 100, 500, 1000]\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])\n",
        "\n",
        "# Loop through different feature counts\n",
        "for num_features in feature_counts:\n",
        "    # Select top N features\n",
        "    top_features = feature_importances.nlargest(num_features).index.tolist()\n",
        "\n",
        "    # Filter dataset with selected features\n",
        "    X_train_selected = X_train[top_features]\n",
        "    X_test_selected = X_test[top_features]\n",
        "\n",
        "    # Train Random Forest classifier\n",
        "    rf_clf = RandomForestClassifier(n_estimators=500, max_depth=None, min_samples_split=2,\n",
        "                                    random_state=42, n_jobs=-1)\n",
        "    rf_clf.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf_clf.predict(X_test_selected)\n",
        "    y_pred_proba = rf_clf.predict_proba(X_test_selected)[:, 1]  # Probability estimates for AUC calculation\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results in DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([[num_features, auc, accuracy, precision, kappa]],\n",
        "                                                      columns=[\"Features\", \"AUC\", \"Accuracy\", \"Precision\", \"Kappa\"])],\n",
        "                                                      ignore_index=True)\n",
        "\n",
        "# Display final results\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "V4OLsv7xZwap"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}